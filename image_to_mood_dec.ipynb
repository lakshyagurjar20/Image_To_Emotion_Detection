{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!pip install -U pip\n",
    "!pip install --index-url https://download.pytorch.org/whl/cu118 torch torchvision torchaudio\n",
    "!pip install mediapipe\n",
    "\n",
    "!pip install -U \\\n",
    "certifi \\\n",
    "charset-normalizer \\\n",
    "cmake \\\n",
    "filelock \\\n",
    "fsspec \\\n",
    "huggingface-hub \\\n",
    "idna \\\n",
    "Jinja2 \\\n",
    "joblib \\\n",
    "kaggle \\\n",
    "lit \\\n",
    "MarkupSafe \\\n",
    "mpmath \\\n",
    "networkx \\\n",
    "numpy \\\n",
    "nvidia-cublas-cu12 \\\n",
    "nvidia-cuda-runtime-cu12 \\\n",
    "nvidia-cudnn-cu12 \\\n",
    "packaging \\\n",
    "pandas \\\n",
    "Pillow \\\n",
    "protobuf \\\n",
    "python-dateutil \\\n",
    "python-slugify \\\n",
    "pytz \\\n",
    "PyYAML \\\n",
    "regex \\\n",
    "requests \\\n",
    "safetensors \\\n",
    "scikit-learn \\\n",
    "scipy \\\n",
    "six \\\n",
    "sympy \\\n",
    "tensorboardX \\\n",
    "text-unidecode \\\n",
    "threadpoolctl \\\n",
    "tokenizers \\\n",
    "torch torchvision torchaudio \\\n",
    "tqdm \\\n",
    "transformers \\\n",
    "triton \\\n",
    "typing_extensions \\\n",
    "tzdata \\\n",
    "urllib3\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "R_Fdy3RxbgbW",
    "outputId": "58f29a36-9ae9-4b9a-b2b2-10693bd09010"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "h5_files = glob.glob(\"./data/*.h5\")\n",
    "all_samples = []\n",
    "all_labels = []\n",
    "\n",
    "def infer_label_from_name(name):\n",
    "    if \"Angry\" in name or \"_an_\" in name:\n",
    "        return 0\n",
    "    elif \"Happy\" in name or \"_ha_\" in name:\n",
    "        return 1\n",
    "    elif \"Neutral\" in name or \"_nu_\" in name:\n",
    "        return 2\n",
    "    elif \"Sad\" in name or \"_sa_\" in name:\n",
    "        return 3\n",
    "    else:\n",
    "        return -1  # unknown\n",
    "\n",
    "for p in h5_files:\n",
    "    print(f\"Processing {p}\")\n",
    "    with h5py.File(p, 'r') as f:\n",
    "        for k in f.keys():\n",
    "            data = f[k][()]\n",
    "\n",
    "            if np.isscalar(data) or data.size == 0:\n",
    "                print(f\"Skipping scalar or empty dataset {p}::{k}\")\n",
    "                continue\n",
    "\n",
    "            if data.ndim == 1:\n",
    "                if data.size == 48:\n",
    "                    data = data.reshape(1, 48)\n",
    "                else:\n",
    "                    print(f\"Skipping 1D dataset with unexpected length: {p}::{k}, length={data.size}\")\n",
    "                    continue\n",
    "\n",
    "            if data.ndim != 2 or data.shape[1] != 48:\n",
    "                print(f\"Skipping dataset with unexpected dims {p}::{k} shape={data.shape}\")\n",
    "                continue\n",
    "\n",
    "            n = data.shape[0]\n",
    "            lbl = infer_label_from_name(k)\n",
    "            if lbl == -1:\n",
    "                print(f\"Skipping dataset with unknown label: {p}::{k}\")\n",
    "                continue\n",
    "\n",
    "            all_samples.append(data.astype('float32'))\n",
    "            all_labels.append(np.full(n, lbl, dtype='int64'))\n",
    "\n",
    "if len(all_samples) == 0:\n",
    "    raise RuntimeError(\"No data read from H5 files!\")\n",
    "\n",
    "X = np.vstack(all_samples)\n",
    "y = np.concatenate(all_labels)\n",
    "\n",
    "print(\"Final shapes:\", X.shape, y.shape)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1E7v7C91lDuj",
    "outputId": "b81a5c31-2ef9-497d-f522-78a2c91860f5",
    "collapsed": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TzoH6DI-nrKc",
    "outputId": "361ba66f-435d-48fe-8b74-21dae96c8329"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "clf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aRVq6-jznzv0",
    "outputId": "a59e2378-86e7-4b45-9c1c-3f8868b23916"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(clf, \"emotion_classifier_rf.pkl\")\n",
    "print(\"Model saved!\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kl8YJpS-qgy2",
    "outputId": "43eab60e-39c4-46d3-d14d-1b4b4e518809"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ],
   "metadata": {
    "id": "4EbTBOX748HF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "print(\"Scaler saved as scaler.pkl\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "noPdfaeh7B5y",
    "outputId": "6fd4f052-ad91-495e-f9c3-ff3ea16ba8df"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "print(os.listdir())\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_XGpil_g7Hb9",
    "outputId": "c8c64fe1-93cb-4baf-f2b8-847037689e67"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "scaler = joblib.load(\"scaler.pkl\")\n",
    "clf = joblib.load(\"emotion_classifier_rf.pkl\")\n"
   ],
   "metadata": {
    "id": "vYdZslwn7K4W"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import joblib\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "model = joblib.load('emotion_classifier_rf.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "def extract_features(results):\n",
    "    features = []\n",
    "    if results.pose_landmarks:\n",
    "        for idx, lm in enumerate(results.pose_landmarks.landmark):\n",
    "            if idx in [0, 11, 12, 13, 14, 15, 16, 23, 24, 25, 26, 27, 28, 29, 30, 31]:\n",
    "                features.extend([lm.x, lm.y, lm.z])\n",
    "    if len(features) != 48:\n",
    "        return None\n",
    "    return np.array(features).reshape(1, -1)\n",
    "\n",
    "video_path = 'testing.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(rgb_frame)\n",
    "    features = extract_features(results)\n",
    "    if features is None:\n",
    "        continue\n",
    "    features_scaled = scaler.transform(features)\n",
    "    prediction = model.predict(features_scaled)[0]\n",
    "\n",
    "    overlay_text = f'Predicted Emotion: {prediction}'\n",
    "    cv2.putText(frame, overlay_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                1.0, (0, 255, 0), 2)\n",
    "\n",
    "    cv2_imshow(frame)\n",
    "\n",
    "\n",
    "cap.release()\n",
    "pose.close()\n",
    "print(\"Video processing done.\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lopggJ4NFPkC",
    "outputId": "da8406e5-1e45-4e97-d520-23d40fb75ea7"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}